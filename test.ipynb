{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4518/4518 [00:00<00:00, 5427.94it/s]\n",
      "4518it [00:00, 500934.88it/s]\n",
      "100%|██████████| 1113/1113 [00:01<00:00, 654.41it/s]\n",
      "100%|██████████| 1113/1113 [00:00<00:00, 1517.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 70s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating face graph: 100%|██████████| 1113/1113 [00:41<00:00, 27.03it/s] \n",
      "creating clusters: 100%|██████████| 1113/1113 [00:00<00:00, 63816.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from face_wrapper import FaceWrapper, FaceProcessor\n",
    "from glob import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from queue import Queue\n",
    "import random\n",
    "from pydantic import BaseModel\n",
    "import datetime\n",
    "\n",
    "FACES_THRESHOLD = 0.70\n",
    "\n",
    "class SearchResult(BaseModel):\n",
    "    id: str\n",
    "    format: str\n",
    "    image_path: str\n",
    "    timestamp: float\n",
    "    score: float\n",
    "    date: datetime.date\n",
    "    location: str\n",
    "\n",
    "class FaceClassifier(object):\n",
    "    def __init__(self, images, filter_height: int = 60, filter_width: int = 60):\n",
    "        self.face_processor = FaceProcessor(images)\n",
    "        self.face_processor.filter(filter_height, filter_width)\n",
    "        self.face_processor.calculate_embeddings()\n",
    "\n",
    "        self.embeddings = self.face_processor.embeddings\n",
    "        self.clusters = self.cluster_faces()\n",
    "        self.clusters = sorted(self.clusters, key=lambda l: (len(l), l), reverse=True)\n",
    "    \n",
    "    def cosine(self, embedding1: np.ndarray, embedding2: np.ndarray):\n",
    "        return torch.cosine_similarity(\n",
    "            torch.tensor(embedding1).unsqueeze(0),\n",
    "            torch.tensor(embedding2).unsqueeze(0)\n",
    "        ).item()\n",
    "\n",
    "    def cluster_faces(self):\n",
    "        \"\"\"\n",
    "        THis function is written by OJU\n",
    "        \"\"\"\n",
    "        list_of_clusters=[]\n",
    "        dic_of_elements_covered={}\n",
    "        graph={}\n",
    "\n",
    "        for emb in tqdm(range(len(self.embeddings)), desc='generating face graph'):\n",
    "            graph[emb] = []\n",
    "\n",
    "            for y in range(emb+1, len(self.embeddings)):\n",
    "                if self.cosine(self.embeddings[emb], self.embeddings[y]) >= FACES_THRESHOLD:\n",
    "                    graph[emb].append(y)\n",
    "\n",
    "        for emb in tqdm(range(len(self.embeddings)), desc='creating clusters'):\n",
    "            lst=[]\n",
    "            if emb in dic_of_elements_covered: continue\n",
    "            \n",
    "            q=Queue()\n",
    "            q.put(emb)\n",
    "\n",
    "            while (not q.empty()):\n",
    "                curr=q.get()\n",
    "                lst.append(curr)\n",
    "                dic_of_elements_covered[curr]=None\n",
    "                for x in graph[curr]:\n",
    "                    if x in dic_of_elements_covered: continue\n",
    "                    q.put(x)\n",
    "\n",
    "            list_of_clusters.append(lst)\n",
    "        \n",
    "        return list_of_clusters\n",
    "\n",
    "    def fetch_top_faces(self, num_faces: int = 10):\n",
    "        clusters = self.clusters[:num_faces]\n",
    "\n",
    "        for cluster in clusters:\n",
    "            index = random.choice(cluster)\n",
    "            path = self.face_processor.filepaths[index]\n",
    "\n",
    "            yield path\n",
    "\n",
    "face_classifier = FaceClassifier(glob(\"images/FACE*.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images\\\\FACE-IcrbM1l_BoI-21b44be0-8df5-4c65-b7b8-22e424fc6ad9-0.jpeg',\n",
       " 'images\\\\FACE-IcrbM1l_BoI-f55a26f8-0094-425f-9ac6-5a25633549d9-0.jpeg',\n",
       " 'images\\\\FACE-a7GITgqwDVg-eaac8895-8e88-4c86-af83-889bf9bfe50b-0.jpeg',\n",
       " 'images\\\\FACE-_GgIt2EFHV8-becd620f-e470-4e97-8b45-e92be4eb1e0a-0.jpeg',\n",
       " 'images\\\\FACE-_GgIt2EFHV8-2c5b4bfb-1833-4e0d-bad0-d0a2f8575686-0.jpeg',\n",
       " 'images\\\\FACE-e-ORhEE9VVg-263bf4ba-9c88-4c42-8103-c30d64b9bcbc-0.jpeg',\n",
       " 'images\\\\FACE-e-ORhEE9VVg-d1eefd45-7f14-4009-b0c2-7687947e444c-1.jpeg',\n",
       " 'images\\\\FACE-e-ORhEE9VVg-e52db5cf-b528-4405-8132-a05b7d9fdd4f-0.jpeg',\n",
       " 'images\\\\FACE-000000092091-5674ab4a-af19-4e50-94da-4341b49808e4-0.jpeg',\n",
       " 'images\\\\FACE-a7GITgqwDVg-656485eb-cc2f-4117-9560-e0be2e313e5f-0.jpeg']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(face_classifier.fetch_top_faces())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
